# Интеграции с BI-инструментами

Начало лекции на 23 00

## Business Intelligence (BI)

У преподавателя есть репа с демо по суперсету.

BI - средство для визуализации тех данных, которые мы получили в рамках СУБД.

Раньше все хранилось на одном большом хранилище (например, Оркале). На нем раскладывались данные (stage - сырые, ods - исторические, dds - очищенные, datamart - мог быть дублем или продолжением ддс). Как раз датамарт и предоставлялся бизнес-пользователям, которые приходили и делали селекты.

Также раньше для визуализаций могли применяться выгрузки в csv и графики в экселе.

BI идеально подходит для кликхауса (и наоборот) для быстрого отображения данных. Без DWH не может быть BI.

От того, насколько у нас красивые графики, зависит и настроение, и время всей компании =)

Требования к BI инструментам
- Поддержка необходимых для проекта коннекторов , функционал (доступность источников - БД, pip install)
- Незатратность настройки (где будет развернуть наш инструмент - чаще всего в кубере)
- Надежность, отказоустойчивость
- Возможность мониторинга (как в целом - через прометеус, графану и тд, так и бизнес метрик)
- Визуал
- Комьюнити, распространенность
- Требования бизнес-пользователей

В Looker есть версионирование кода!

## Интеграции с кликхаусом (56 00)

[ссылка](https://clickhouse.com/use-cases/business-intelligence)

## Конфигурация

Администрирование:
- Настройка подключений к источникам
- Добавление и удаление пользователей
- Аутентификация пользователей
- Настройка доступов и полномочий пользователей
- Конфигурация уведомлений на почту / мессенджеры

Сопровождение решения (Operations, Ops):
- Установка ПО и обновление версий (миграция)
- Конфигурирование внутренних БД (для метаданных)
- Настройка шифрования данных
- Управление форматами представления данных

## Практика (1 03 00)

Туториал есть здесь

Суперсет обновляется достаточно часто!

Установка суперсета идет в несколько этапов
1. закачать образ и поднять его с перенаправлением портов и переменными окружения. Важно поднимать с SUPERSET_SECRE_KEY
```
sudo docker pull apache/superset
sudo docker run -d -p 8080:8088 -e "SUPERSET_SECRET_KEY=your_secret_key_here" --name superset apache/superset
```
2. Суперсету нужна база для метаданных, куда будет складываться инфа о пользователях, логах и тд. Чаще всего ставится постгрес. Также часто ставят redis чтобы быстро обмениваться информацией между процессами всего нашего решения.
3. создается первый пользователь (админский). При этом пока мы не приведем в соответствие БД и не сделаем инит - будет пятисотить!
```
sudo docker exec -it superset superset fab create-admin \
          --username admin \
          --firstname Superset \
          --lastname Admin \
          --email admin@superset.com \
          --password admin

sudo docker exec -it superset superset db upgrade
sudo docker exec -it superset superset load_examples
sudo docker exec -it superset superset init
```

По умолчанию суперсет поддерживает несколько источников (постгрес, sqlite, престо), все остальное обычно нужно доставлять (поддерживаемые источники [тут](https://superset.apache.org/docs/configuration/databases/)). Так как суперсет написан на питоне - нужно выполнить команду `pip install clickhouse-connect` и рестартануть контейнер.

Connection string to add new Clickhouse - clickhouse+native://login:password@host:9000/ or clickhousedb://{username}:{password}@{hostname}:{port}/{database}

Еще из плюшек суперсета - хорошее апи (по апи можно делать запрос на текущее состояние датасетов, на какие то текущие значения, общее количество и тд)

1 19 00 - работа на поднятом суперсете

Дашборды с суперсета можно встраивать на какие то сайты (через html)!

По ролям - роль Public чаще всего используется для аутентификации. Alfa - чуть меньше чем в админе. Обычно берется Gamma, убирается все на запись, следующая роль - для конкретных данных, которые у нас здесь есть (`can read on Dataset имя_датасета`). Под каждый датасет создается отдельная роль и дается конкретным пользователям, которым она нужна.

Database connections. Здесь создаем новое подключение (other - здесь можем попробовать через sqlalchemy uri или по обычному (порт 8123)). В sql lab отключаем все ddl, dml! Оставляем только `allow this database to be explored`. Cache Timeout - будет храниться на стороне суперсета. По таймауту кэша стоит исходить от частоты запросов бизнес пользователей. `cancel query on window unload event` - ВКЛЮЧАЕМ ВСЕГДА! В sequrity можно настроить инперсонацию - чтобы если пользователь запустил запрос под общим пользователем - мы могли понять, кто именно запустил запрос (будет попадать session_id в session_log).

Делаем простую визуализацию - линейную зависимость pickup_datetime. Идем в датасеты. СОздается датасет и создается сразу чарт, с которым будем работать (диаграмма). На практике пошли по ленивому пути - без написания sql кода. При сохранении чарта можем сразу перейти на датасет.

В датасете есть понятия драфт и паблишд. Драфт - это когда мы не хотим чтобы пользователи видели изменения.

Отобразить легенду - чарт, кастомайз, легенда

Репозиторий редаша https://github.com/getredash/redash 

## ДЗ 

Датасет любой, но трипс не принимается =) Нужно сделать 5 различных визуализаций.