# Интеграция с Кафка и подводные камни

## Поток данных

- Поток данных (stream) — ÿто именованнýй набор сообщений.
- Поток — неограниченнýй набор записей
- Пакет — конечнýй набор записей

Можно не пускать пользователя к себе, а пускать данные просто в кафку! Таким образом получается распределенный отказоустойчивый пайплаен.

Kafka Streams - это по сути потоковая обработка внутри кафки (из топика в топик, без перекидывания в другие хранилища).

softwaremill.com/kafka-visualisation - хорошая визуализация по кафке

Есть кафка с КРафтом (Kafka с KRaft). Рафт - процесс, заменяющий зукипер
- Kafka сервер может быть:
  - broker
  - controller (3 или 5)
  - broker, controller (для разработки)
- Узлы контроллера - кворум Raft
- Журнал метаданных - информация каждом изменении метаданных кластера
- Активный контроллер - лидер Raft

В потоковой отправке сообщений есть гарантия доставки сообщений. Есть 3 различных гарантий доставки
- exactly once (одно сообщение есть и одно сообщение получается - у нас не будет никаких пропусков или дублей)
- at most once (если и придет - то максимум в одном экземпляре, но может и не дойти) (если теряются данные - то обычно это большая проблема!)
- at least once (точно придет, но непонятно в каком количестве)

При записи есть принцип под названием acknowledgement - принцип как метаинформация нам отправляется. Ack указывается равным 0 (нам все равно, записалось ли сообщение на лидирующий брокер - делается когда данных много и нам лишь бы их запихнуть, потеря некритична), 1 (когда записали и проверили на лидирующем брокере, что на зависимых брокерах - нас не интересует)(что то среднее между ценой и качеством, редко используется) или all (проверили и на лидирующем, и на зависимых брокерах). Такой же принцип и на консьюмерах.

Принцип, как мы выбираем количество консьюмеров в kafka engine (`kafka_num_consumers`). Есть важное правило, один консьюмер может читать инфу из всех партиций, но партиция сама по себе может быть прочитана лишь одним консьюмером! От этого зависит выбор количества консьюмеров. Укажем меньше консьюмеров чем количество партиций - у нас будет какой то из консьюмеров больше работать, больше консьюмеров - кто то будет простаивать. Лучше всег выбирать количество консьюмеров равное количеству партиций.

## Варианты установки 56 00

курсы по кафке сейчас на 24 лекции! Кафка - достаточно сложный инструмент. Мы должны запустить как минимум 2 инструмента - кафка и зукипер.

Основные операции
- zookeeper-server-start.sh – запуск Zookeeper
- zookeeper-server-stop.sh – останов Zookeeper
- kafka-server-start.sh – запуск Kafka брокера
- kafka-server-stop.sh – останов Kafka брокера
- kafka-console-producer.sh – консолþнýй Producer
- kafka-console-consumer.sh – консолþнýй Consumer
- kafka-topics.sh – работа с темами (создатþ, удалитþ, изменитþ, посмотретþ)

Для запуска кафки в докере есть хороший репозиторий, https://github.com/conduktor/kafka-stack-docker-compose , с различными вариантами по количеству зукиперов и кафок.

И еще есть репозиторий по [кафке](https://github.com/OtusTeam/OTUS-Kafka) от отуса.

1 01 00 - поднятие кафки в облаке

Можно разместить на одном зукипере и кафку, и клик!

1 03 00 интеграция с кликом.

Кафка движок - это просто клиентское приложение (консьюмер) для кафки. Сам по себе он информацию не содержит и напрямую к нему запрашиваться нельзя!

Взаимодействие кафка и кликхаус, Self-managed Kafka Connectivity
- [Kafka Connect](https://clickhouse.com/docs/en/integrations/kafka/clickhouse-kafka-connect-sink) - ÿто бесплатнýй компонент Apache Kafka с открýтýм исходнýм кодом, которýй работает как централизованнýй датахаб длā простой интеграции даннýх между Kafka и другими системами даннýх.
- [Vector](https://clickhouse.com/docs/en/integrations/kafka/kafka-vector) - конвейер даннýх, не зависāщий от источника. Благодарā возможности чтениā из Kafka и отправки собýтий в ClickHouse он представлāет собой надежнýй вариант интеграции.
- [JDBC Connect Sink](https://clickhouse.com/docs/en/integrations/kafka/kafka-connect-jdbc) - позволāет ÿкспортироватþ даннýе из топиков Kafka в лĀбуĀ релāционнуĀ базу даннýх с драйвером JDBC.
- Custom code - В случаāх, когда требуетсā полþзователþскаā обработка собýтий, может бýтþ исполþзован полþзователþский код с исполþзованием соответствуĀщих клиентских библиотек длā Kafka и ClickHouse.
- Kafka table engine обеспечивает нативнуĀ интеграциĀ ClickHouse (недоступна в ClickHouse Cloud). Но! Сталкивались с потерей данных и не совсем корректным поведением. Плюс используется одно ядро и процессы не параллелятся.

1 16 00 практика, настройка (на яндекс облаке)

была доработка конфига чтобы читать sasl_ssl !